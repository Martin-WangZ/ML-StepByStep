{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3  C4.5 CART  Implement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT():\n",
    "    def __init__(self,x,maxDepth=3,minGain=0.5):\n",
    "        self.__maxDepth=maxDepth\n",
    "        self.__minGain=minGain\n",
    "        self.__depth=0\n",
    "        self.__tree=[]\n",
    "        self.__features=np.arrage(x.shape[1])\n",
    "\n",
    "    # given the y in that dataset , compute the entropy\n",
    "    def _entropy(self,y):\n",
    "        values,counts=np.unique(y,return_counts=True)\n",
    "        total=len(y)\n",
    "        entropy=-np.sum([count/total*np.log2(count/total) for count in counts])\n",
    "        return entropy\n",
    "    # given attribute index and that dataset(x,y), compute conditional entropy\n",
    "    def _conditEntropy(self,attribute,x,y):\n",
    "        values=np.unique(x[:,attribute])\n",
    "        entropy=[]\n",
    "        # iterate each value in that attribute\n",
    "        for value in values:\n",
    "            index=np.argwhere(value==x[:,attribute]).reshape(-1)\n",
    "            # how many data points belongs to that attribute value\n",
    "            label=y[index]\n",
    "            weight=len(label)/len(y)\n",
    "            h=self._entropy(label)\n",
    "            attrEntrop=weight*h\n",
    "            entropy.append(attrEntrop)\n",
    "        conditEntropy=np.sum(entropy)\n",
    "        return conditEntropy\n",
    "    def id3Train(self,x,y):\n",
    "        # if all data belong to one class, then return\n",
    "        values,counts=np.unique(y,return_counts=True)\n",
    "        # if only a class, return the tree\n",
    "        if len(values)==1:\n",
    "            # depth and its class\n",
    "            if self.__depth==0:\n",
    "                self.__tree.append((self.__depth,'Root Node',values.item()))\n",
    "            else:\n",
    "                self.__tree.append((self.__depth,'Leaf Node',values.item()))\n",
    "            return self.__tree\n",
    "        # if no features, return, # if it is root, it is impossible the length of feature is 0\n",
    "        elif len(self.__features)==0:\n",
    "            valMaxCount=values[np.argmax(counts)]\n",
    "            self.__tree.append((self.__depth,'Leaf Node',valMaxCount))\n",
    "            return self.__tree\n",
    "        else:\n",
    "            # 1. compute data entropy\n",
    "            h=self._entropy(y)\n",
    "            # 2. compute conditional entropy of each feature\n",
    "            conEL=[]\n",
    "            for feature in self.__features:\n",
    "                conditEntropy=self._conditEntropy(feature,x,y)\n",
    "                conEL.append(conditEntropy)\n",
    "            # 3. compute gain\n",
    "            gain=h-np.array(conEL)\n",
    "            # 4. max gain\n",
    "            maxGain=np.max(gain)\n",
    "            # if max gain less than threshold\n",
    "            if maxGain<=self.__minGain:\n",
    "                valMaxCount=values[np.argmax(counts)]\n",
    "                if self.__depth==0:\n",
    "                    self.__tree.append((self.__depth,'Root Node',valMaxCount))\n",
    "                else:\n",
    "                    self.__tree.append((self.__depth,'Leaf Node',valMaxCount))\n",
    "                return self.__tree\n",
    "            # else split the to sub-nodes\n",
    "            else:\n",
    "                # depth + 1\n",
    "                self.__depth+=1\n",
    "                # 5. get feature with max gain and set it as standard to split data\n",
    "                maxGainF=self.__features[np.argmax(gain)]\n",
    "                # 6. according to the feature values to split dataset\n",
    "                attrValues=np.unique(x[:,maxGainF])\n",
    "\n",
    "                for attrValue in attrValues:\n",
    "                    xAttrIndex=np.argwhere(attrValue==x[:,maxGainF])\n",
    "                    xsub=x[xAttrIndex,:]\n",
    "                    ysub=y[xAttrIndex]\n",
    "                    subvals,subcts=np.unique(ysub,return_counts=True)\n",
    "                    val=subvals[np.argmax(subcts)]\n",
    "                    self.__tree.append((self.__depth,maxGainF,val))\n",
    "                    leftF=np.argwhere(maxGainF!=self.__features)\n",
    "                    self.__features=np.array(self.__features)[leftF].tolist()\n",
    "                    self.id3Train(xsub,ysub)\n",
    "    def c45(self):\n",
    "        pass\n",
    "    def regTree(self):\n",
    "        pass\n",
    "    def clsTree(self):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Machine-Learning)",
   "language": "python",
   "name": "pycharm-b417c3b3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}